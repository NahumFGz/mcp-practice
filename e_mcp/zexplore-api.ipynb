{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langgraph.graph import StateGraph, MessagesState, START\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "async def process_query(query: str, server_configs=None):\n",
    "    \"\"\"\n",
    "    Process a query using the MCP client and LangGraph\n",
    "    \n",
    "    Args:\n",
    "        query: The user query to process\n",
    "        server_configs: Dictionary of server configurations, defaults to math and transparencia servers\n",
    "        \n",
    "    Returns:\n",
    "        The response from the graph\n",
    "    \"\"\"\n",
    "    if server_configs is None:\n",
    "        server_configs = {\n",
    "            \"math\": {\n",
    "                \"command\": \"python\",\n",
    "                \"args\": [\"./math_server.py\"],\n",
    "                \"transport\": \"stdio\",\n",
    "            },\n",
    "            \"transparencia\": {\n",
    "                \"command\": \"python\",\n",
    "                \"args\": [\"./mcp_server_transparencia.py\"],\n",
    "                \"transport\": \"stdio\",\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    # Initialize the chat model\n",
    "    model = init_chat_model(\"openai:gpt-4o-mini\")\n",
    "    \n",
    "    # Create a fresh client and graph for each query\n",
    "    async with MultiServerMCPClient(server_configs) as client:\n",
    "        tools = client.get_tools()\n",
    "        \n",
    "        def call_model(state: MessagesState):\n",
    "            response = model.bind_tools(tools).invoke(state[\"messages\"])\n",
    "            return {\"messages\": response}\n",
    "        \n",
    "        # Build the graph\n",
    "        builder = StateGraph(MessagesState)\n",
    "        builder.add_node(call_model)\n",
    "        builder.add_node(ToolNode(tools))\n",
    "        builder.add_edge(START, \"call_model\")\n",
    "        builder.add_conditional_edges(\n",
    "            \"call_model\", \n",
    "            tools_condition,\n",
    "        )\n",
    "        builder.add_edge(\"tools\", \"call_model\")\n",
    "        graph = builder.compile()\n",
    "        \n",
    "        # Process the query\n",
    "        response = await graph.ainvoke({\"messages\": query})\n",
    "        return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Cuantos contratos tiene el proveedor con ruc 20500000001?', additional_kwargs={}, response_metadata={}, id='e27ee8f3-3f48-4d1a-ac03-df2613dc1ed5'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_x7whewpIIQUR7lOM8GWM5N0W', 'function': {'arguments': '{\"ruc\":\"20500000001\"}', 'name': 'buscar_contratos_por_ruc'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 165, 'total_tokens': 189, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'id': 'chatcmpl-BV7RXg9syGt4W4I1jyMjCnBAEqbeL', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--9f2ba7d2-de5c-4b55-98b3-16b57c5cd75f-0', tool_calls=[{'name': 'buscar_contratos_por_ruc', 'args': {'ruc': '20500000001'}, 'id': 'call_x7whewpIIQUR7lOM8GWM5N0W', 'type': 'tool_call'}], usage_metadata={'input_tokens': 165, 'output_tokens': 24, 'total_tokens': 189, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='{\\n  \"ruc\": \"20500000001\",\\n  \"total_contratos\": 42,\\n  \"monto_total\": 1250000.5,\\n  \"entidades_top\": [\\n    \"MINSA\",\\n    \"Gobierno Regional de Lima\"\\n  ]\\n}', name='buscar_contratos_por_ruc', id='3993a0c5-e7af-49dc-825e-b25fd06a3d4b', tool_call_id='call_x7whewpIIQUR7lOM8GWM5N0W'),\n",
       "  AIMessage(content='El proveedor con RUC 20500000001 tiene un total de 42 contratos.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 259, 'total_tokens': 279, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'id': 'chatcmpl-BV7RYlE9PNAQucz7skguPmFQQ8Sk6', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--7cc2814e-b7e6-499c-89cb-dbe148735cd2-0', usage_metadata={'input_tokens': 259, 'output_tokens': 20, 'total_tokens': 279, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transparencia_response = await process_query(\"Cuantos contratos tiene el proveedor con ruc 20500000001?\")\n",
    "transparencia_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Puedes darme la asistencia del congresista Soto ', additional_kwargs={}, response_metadata={}, id='1af9f3f5-e349-42d4-b50a-5cdaae5569c6'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_YOJbQoMjmLvepX3js1zVRr0e', 'function': {'arguments': '{\"nombre\":\"Soto\"}', 'name': 'obtener_asistencias_congresista'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 160, 'total_tokens': 181, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'id': 'chatcmpl-BV7RZVePVemYD1WgM5lIUtregu8Bv', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--0ecdc00d-54b4-4cc4-a6fd-b21a8427d3e9-0', tool_calls=[{'name': 'obtener_asistencias_congresista', 'args': {'nombre': 'Soto'}, 'id': 'call_YOJbQoMjmLvepX3js1zVRr0e', 'type': 'tool_call'}], usage_metadata={'input_tokens': 160, 'output_tokens': 21, 'total_tokens': 181, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='{\\n  \"nombre\": \"Soto\",\\n  \"asistencias\": 152,\\n  \"faltas\": 17,\\n  \"licencias\": 4,\\n  \"asistencia_pct\": 88.4\\n}', name='obtener_asistencias_congresista', id='9a2528fb-cc27-42b1-899a-bbd79aa8b41a', tool_call_id='call_YOJbQoMjmLvepX3js1zVRr0e'),\n",
       "  AIMessage(content='El congresista Soto tiene un total de 152 asistencias, 17 faltas y 4 licencias. Su porcentaje de asistencia es del 88.4%.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 240, 'total_tokens': 276, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'id': 'chatcmpl-BV7RaVbuWlZ79YC2hFpAjXumw5psL', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--e8317500-ced0-4085-8e01-b4c0ac270e03-0', usage_metadata={'input_tokens': 240, 'output_tokens': 36, 'total_tokens': 276, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transparencia_response = await process_query(\"Puedes darme la asistencia del congresista Soto \")\n",
    "transparencia_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forma 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langgraph.graph import StateGraph, MessagesState, START\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain.chat_models import init_chat_model\n",
    "import asyncio\n",
    "\n",
    "class MCPQueryProcessor:\n",
    "    \"\"\"\n",
    "    Clase para procesar consultas utilizando MultiServerMCPClient de manera eficiente.\n",
    "    Mantiene el cliente y el grafo activos para m√∫ltiples consultas.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, server_configs=None):\n",
    "        \"\"\"\n",
    "        Inicializa el procesador de consultas MCP\n",
    "        \n",
    "        Args:\n",
    "            server_configs: Diccionario de configuraciones de servidores\n",
    "        \"\"\"\n",
    "        if server_configs is None:\n",
    "            self.server_configs = {\n",
    "                \"math\": {\n",
    "                    \"command\": \"python\", \n",
    "                    \"args\": [\"./math_server.py\"], \n",
    "                    \"transport\": \"stdio\",\n",
    "                },\n",
    "                \"transparencia\": {\n",
    "                    \"command\": \"python\", \n",
    "                    \"args\": [\"./mcp_server_transparencia.py\"], \n",
    "                    \"transport\": \"stdio\",\n",
    "                }\n",
    "            }\n",
    "        else:\n",
    "            self.server_configs = server_configs\n",
    "            \n",
    "        self.client = None\n",
    "        self.graph = None\n",
    "        self.model = init_chat_model(\"openai:gpt-4.1\")\n",
    "        \n",
    "    async def __aenter__(self):\n",
    "        \"\"\"M√©todo para iniciar el cliente y construir el grafo\"\"\"\n",
    "        self.client = MultiServerMCPClient(self.server_configs)\n",
    "        await self.client.__aenter__()\n",
    "        \n",
    "        # Obtener herramientas del cliente\n",
    "        tools = self.client.get_tools()\n",
    "        \n",
    "        # Definir la funci√≥n de llamada al modelo\n",
    "        def call_model(state: MessagesState):\n",
    "            response = self.model.bind_tools(tools).invoke(state[\"messages\"])\n",
    "            return {\"messages\": response}\n",
    "        \n",
    "        # Construir el grafo\n",
    "        builder = StateGraph(MessagesState)\n",
    "        builder.add_node(call_model)\n",
    "        builder.add_node(ToolNode(tools))\n",
    "        builder.add_edge(START, \"call_model\")\n",
    "        builder.add_conditional_edges(\n",
    "            \"call_model\", \n",
    "            tools_condition,\n",
    "        )\n",
    "        builder.add_edge(\"tools\", \"call_model\")\n",
    "        self.graph = builder.compile()\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    async def __aexit__(self, exc_type, exc_val, exc_tb):\n",
    "        \"\"\"Cerrar el cliente al salir\"\"\"\n",
    "        if self.client:\n",
    "            await self.client.__aexit__(exc_type, exc_val, exc_tb)\n",
    "            \n",
    "    async def process_query(self, query: str):\n",
    "        \"\"\"\n",
    "        Procesar una consulta usando el grafo existente\n",
    "        \n",
    "        Args:\n",
    "            query: La consulta del usuario\n",
    "        \n",
    "        Returns:\n",
    "            La respuesta del grafo\n",
    "        \"\"\"\n",
    "        if not self.graph:\n",
    "            raise RuntimeError(\"El procesador no est√° inicializado. Usa 'async with' primero.\")\n",
    "            \n",
    "        response = await self.graph.ainvoke({\"messages\": query})\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Cuantos contratos tiene el proveedor con ruc 20500000001?', additional_kwargs={}, response_metadata={}, id='9ba55fa0-fdd6-4cff-8659-4ebc8a526bbb'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_twJp0HIn3XRv73eryMRUz202', 'function': {'arguments': '{\"ruc\":\"20500000001\"}', 'name': 'buscar_contratos_por_ruc'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 165, 'total_tokens': 189, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_a1102cf978', 'id': 'chatcmpl-BV7WBhZ9ld8GIVarFTC7Af1KhlPYC', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--d5fb946a-4293-40e4-b171-a21a531fdb3b-0', tool_calls=[{'name': 'buscar_contratos_por_ruc', 'args': {'ruc': '20500000001'}, 'id': 'call_twJp0HIn3XRv73eryMRUz202', 'type': 'tool_call'}], usage_metadata={'input_tokens': 165, 'output_tokens': 24, 'total_tokens': 189, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='{\\n  \"ruc\": \"20500000001\",\\n  \"total_contratos\": 42,\\n  \"monto_total\": 1250000.5,\\n  \"entidades_top\": [\\n    \"MINSA\",\\n    \"Gobierno Regional de Lima\"\\n  ]\\n}', name='buscar_contratos_por_ruc', id='332210bc-40b6-46ff-a24e-63c660763070', tool_call_id='call_twJp0HIn3XRv73eryMRUz202'),\n",
       "  AIMessage(content='El proveedor con RUC 20500000001 tiene un total de 42 contratos.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 259, 'total_tokens': 279, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_a1102cf978', 'id': 'chatcmpl-BV7WCrp6E8ZFJBYY3kzgnDKwFYtJj', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--54c9747c-5f3d-4f3c-98f5-955f2dc0f2da-0', usage_metadata={'input_tokens': 259, 'output_tokens': 20, 'total_tokens': 279, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "async with MCPQueryProcessor() as processor:\n",
    "    transparencia_response = await processor.process_query(\"Cuantos contratos tiene el proveedor con ruc 20500000001?\")\n",
    "\n",
    "transparencia_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_mcptesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
